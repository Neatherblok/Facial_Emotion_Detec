{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d2f3f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install datasets\n",
    "#!pip install --upgrade --force-reinstall huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "409baa23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision.transforms import transforms, Lambda, Resize\n",
    "from torchvision import datasets, transforms, models\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Specify where to find the data preparation class\n",
    "import sys\n",
    "sys.path.append('Preparation')\n",
    "from Preparation import CustomDataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9330ac4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet50 training data (ImageNet) properties\n",
    "MEAN = [0.485, 0.456, 0.406]\n",
    "STD = [0.229, 0.224, 0.225]\n",
    "#DIMENSIONS = 3\n",
    "#SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47933d25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 877, 'test': 225}\n",
      "['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n",
      "Train Data Loader:\n",
      "Batch Index: 0\n",
      "Inputs Shape: torch.Size([32, 3, 299, 299])\n",
      "Labels Shape: torch.Size([32])\n",
      "Labels: tensor([3, 0, 2, 6, 5])\n",
      "Batch Index: 1\n",
      "Inputs Shape: torch.Size([32, 3, 299, 299])\n",
      "Labels Shape: torch.Size([32])\n",
      "Labels: tensor([0, 0, 2, 2, 6])\n",
      "Batch Index: 2\n",
      "Inputs Shape: torch.Size([32, 3, 299, 299])\n",
      "Labels Shape: torch.Size([32])\n",
      "Labels: tensor([6, 4, 5, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "dataloaders = {x: CustomDataLoader(data_path=\"FER2013\", batch_size=32, dataset_type=x, mean=MEAN, std=STD, dimensions=3).data_loader for x in ['train', 'test']}\n",
    "dataset_sizes = {x: len(dataloaders[x]) for x in ['train', 'test']}\n",
    "print(dataset_sizes)\n",
    "\n",
    "class_names = dataloaders['train'].dataset.classes\n",
    "print(class_names)\n",
    "\n",
    "# Confirm correct data load\n",
    "print(\"Train Data Loader:\")\n",
    "for batch_idx, (inputs, labels) in enumerate(dataloaders['train']):\n",
    "    print(\"Batch Index:\", batch_idx)\n",
    "    print(\"Inputs Shape:\", inputs.shape)\n",
    "    print(\"Labels Shape:\", labels.shape)\n",
    "    # Print the first few labels in the batch\n",
    "    print(\"Labels:\", labels[:5])\n",
    "    # Break after printing a few batches\n",
    "    if batch_idx == 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dae2afde",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\suren\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\suren\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Load the pre-trained ResNet-50 model\n",
    "model = models.resnet50(pretrained=True)\n",
    "\n",
    "# Freeze all layers except the final classification layer\n",
    "for name, param in model.named_parameters():\n",
    "    if \"fc\" in name:  # Unfreeze the final classification layer\n",
    "        param.requires_grad = True\n",
    "    else:\n",
    "        param.requires_grad = False\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)  # Use all parameters\n",
    "\n",
    "\n",
    "# Move the model to the GPU if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "884a62a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 59.7414 Acc: 9.4413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|███████▌                                                                    | 1/10 [2:16:39<20:29:52, 8199.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 52.9880 Acc: 11.7600\n",
      "train Loss: 51.6626 Acc: 11.8506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|███████████████▏                                                            | 2/10 [4:26:04<17:39:12, 7944.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 49.5329 Acc: 12.8889\n",
      "train Loss: 50.0055 Acc: 12.6408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██████████████████████▊                                                     | 3/10 [6:29:48<14:59:06, 7706.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 50.0813 Acc: 12.7378\n",
      "train Loss: 49.1659 Acc: 12.9909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|██████████████████████████████▍                                             | 4/10 [8:35:00<12:42:58, 7629.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 48.2507 Acc: 13.1644\n",
      "train Loss: 48.4807 Acc: 13.2748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████████████████████▌                                     | 5/10 [10:39:36<10:31:11, 7574.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 48.6933 Acc: 13.2400\n",
      "train Loss: 48.0461 Acc: 13.4458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████████████████████████▌                              | 6/10 [12:46:16<8:25:32, 7583.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 49.8573 Acc: 12.8000\n",
      "train Loss: 47.6542 Acc: 13.6716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|█████████████████████████████████████████████████████▏                      | 7/10 [14:58:29<6:24:52, 7697.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 48.1745 Acc: 13.6311\n",
      "train Loss: 47.3691 Acc: 13.7674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████████████████████████████████████████████████████████▊               | 8/10 [17:16:47<4:22:56, 7888.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 47.0777 Acc: 13.6933\n",
      "train Loss: 47.1678 Acc: 13.8734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████████████████████████████████████████████████████████████████▍       | 9/10 [19:35:04<2:13:36, 8016.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 46.8641 Acc: 13.8533\n",
      "train Loss: 46.7471 Acc: 14.0912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 10/10 [21:53:01<00:00, 7878.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 46.6677 Acc: 14.0133\n",
      "Training complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    for phase in ['train', 'test']:\n",
    "        if phase == 'train':\n",
    "            model.train()\n",
    "        else:\n",
    "            model.eval()\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "\n",
    "        for inputs, labels in dataloaders[phase]:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with torch.set_grad_enabled(phase == 'train'):\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        epoch_loss = running_loss / dataset_sizes[phase]\n",
    "        epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "        print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb613f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "torch.save(model.state_dict(), 'ResNet50.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2992aaf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
