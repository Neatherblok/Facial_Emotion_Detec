{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e1b17fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install datasets\n",
    "#!pip install --upgrade --force-reinstall huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77977b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision.transforms import transforms, Lambda, Resize\n",
    "from torchvision import datasets, transforms, models\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class CustomDataLoader:\n",
    "    def __init__(self, data_path, batch_size, dataset_type):\n",
    "        self.data_path = data_path\n",
    "        self.batch_size = batch_size\n",
    "        self.dataset_type = dataset_type\n",
    "\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((48, 48)),  # Resize to size 48x48\n",
    "            transforms.Grayscale(),  # Convert all images to grayscale format\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485], std=[0.2295])\n",
    "        ])\n",
    "\n",
    "        self.dataset = torchvision.datasets.ImageFolder(root=f\"{self.data_path}/{dataset_type}\", transform=self.transform)\n",
    "\n",
    "        if self.dataset_type == 'train':\n",
    "            shuffle = True\n",
    "        else:\n",
    "            shuffle = False\n",
    "\n",
    "        self.data_loader = DataLoader(self.dataset, batch_size=self.batch_size, shuffle=shuffle, num_workers=4)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.dataset[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95578560",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09280971",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'FER2013'\n",
    "\n",
    "# Create data loaders\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'test']}\n",
    "#image_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b78e8a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 28044, 'test': 7177}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4, shuffle=True, num_workers=4) for x in ['train', 'test']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'test']}\n",
    "print(dataset_sizes)\n",
    "\n",
    "class_names = image_datasets['train'].classes\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "19378da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained ResNet-18 model\n",
    "model = models.resnet18(pretrained=True)\n",
    "\n",
    "# Freeze all layers except the final classification layer\n",
    "for name, param in model.named_parameters():\n",
    "    if \"fc\" in name:  # Unfreeze the final classification layer\n",
    "        param.requires_grad = True\n",
    "    else:\n",
    "        param.requires_grad = False\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)  # Use all parameters\n",
    "\n",
    "\n",
    "# Move the model to the GPU if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c30a515e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.9736 Acc: 0.2720\n",
      "test Loss: 2.0504 Acc: 0.2863\n",
      "train Loss: 1.9837 Acc: 0.2708\n",
      "test Loss: 1.7590 Acc: 0.3619\n",
      "train Loss: 1.9647 Acc: 0.2777\n",
      "test Loss: 2.0131 Acc: 0.3050\n",
      "train Loss: 1.9777 Acc: 0.2734\n",
      "test Loss: 1.9535 Acc: 0.2923\n",
      "train Loss: 1.9782 Acc: 0.2729\n",
      "test Loss: 1.9744 Acc: 0.3364\n",
      "train Loss: 1.9651 Acc: 0.2774\n",
      "test Loss: 1.9170 Acc: 0.3404\n",
      "train Loss: 1.9794 Acc: 0.2746\n",
      "test Loss: 1.6945 Acc: 0.3531\n",
      "train Loss: 1.9776 Acc: 0.2730\n",
      "test Loss: 1.7904 Acc: 0.3614\n",
      "train Loss: 1.9751 Acc: 0.2788\n",
      "test Loss: 1.8837 Acc: 0.3256\n",
      "train Loss: 1.9799 Acc: 0.2745\n",
      "test Loss: 1.8934 Acc: 0.3216\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    for phase in ['train', 'test']:\n",
    "        if phase == 'train':\n",
    "            model.train()\n",
    "        else:\n",
    "            model.eval()\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "\n",
    "        for inputs, labels in dataloaders[phase]:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with torch.set_grad_enabled(phase == 'train'):\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        epoch_loss = running_loss / dataset_sizes[phase]\n",
    "        epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "        print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7b6aa588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "torch.save(model.state_dict(), 'Image_classification_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eab2c9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
